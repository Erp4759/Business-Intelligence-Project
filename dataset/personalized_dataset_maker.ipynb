{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b95e365d",
   "metadata": {},
   "source": [
    "## VAESTA Project: Personalized Garment Dataset Creation\n",
    "\n",
    "This notebook uses the Gemini Vision model to analyze user-provided images of single clothing items, extract visual attributes, and compute derived features (like warmth, comfort, and layering scores) to create a rich, structured JSON dataset.\n",
    "\n",
    "0. Initial Setup\n",
    "\n",
    "Install Dependencies (Run this cell once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a737b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow google-generativeai tqdm pandas --quiet\n",
    "!pip install openai --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cba4f9",
   "metadata": {},
   "source": [
    "Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6546d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API configured (model placeholder: gpt-4o-mini)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "OPENAI_API_KEY = \"sk-proj-REPLACE_WITH_YOUR_ACTUAL_OPENAI_KEY\"  # Replace with your actual OpenAI API key\n",
    "# IMAGE_DIR = Path(\"simulated_wardrobes/Female_Wardrobe/\")\n",
    "# OUTPUT_FILE = Path(\"personalized_clothing_dataset_demale.json\")\n",
    "IMAGE_DIR = Path(\"simulated_wardrobes/Male_Wardrobe\")\n",
    "OUTPUT_FILE = Path(\"personalized_clothing_dataset_male.json\")\n",
    "MODEL_NAME = \"gpt-4o-mini\"  # OpenAI vision model\n",
    "\n",
    "# Ensure image directory exists\n",
    "if not IMAGE_DIR.is_dir():\n",
    "    print(f\"Creating image directory at {IMAGE_DIR}. Please add your images now.\")\n",
    "    IMAGE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --- Configure OpenAI ---\n",
    "try:\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    print(f\"OpenAI API configured (model: {MODEL_NAME})\")\n",
    "except Exception as e:\n",
    "    print(f\"Error configuring OpenAI: {e}\")\n",
    "    # Exit or handle error if API key is invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1db3e",
   "metadata": {},
   "source": [
    "1. Feature Engineering Logic\n",
    "\n",
    "These functions translate the raw visual attributes extracted by Gemini (Category, Material, Pattern) into the required quantitative scores (Warmth, Impermeability, Comfort, and Layering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7a0adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping to determine basic garment type\n",
    "OUTER_GARMENTS = [\"coat\", \"jacket\", \"cardigan\", \"blazer\", \"hoodie\"]\n",
    "\n",
    "def determine_outer_inner(category):\n",
    "    \"\"\"Classifies a garment as 'outer' or 'inner' based on category.\"\"\"\n",
    "    category = category.lower()\n",
    "    if category in OUTER_GARMENTS:\n",
    "        return \"outer\"\n",
    "    elif category in [\"dress\", \"skirt\", \"pants\", \"shorts\", \"shoes\", \"accessory\"]:\n",
    "        return \"not-applicable\" # E.g., not an upper body layer\n",
    "    return \"inner\" # Default for t-shirts, shirts, sweaters, etc.\n",
    "\n",
    "def compute_warmth_score(material, category):\n",
    "    \"\"\"Calculates a warmth score (1-5) based on material and garment type.\"\"\"\n",
    "    fabric_scores = {\"denim\":3,\"cotton\":2,\"leather\":4,\"furry\":5,\"wool\":5,\"knit\":4,\"chiffon\":1,\"synthetic\":3,\"silk\":2,\"linen\":1,\"other\":2}\n",
    "    \n",
    "    base_score = fabric_scores.get(material.lower(), 2)\n",
    "    \n",
    "    if category.lower() in OUTER_GARMENTS:\n",
    "        base_score += 2 # Outer garments typically add more warmth\n",
    "    elif category.lower() == \"dress\":\n",
    "        base_score += 1 # Dresses cover a large area\n",
    "        \n",
    "    return min(max(1, base_score), 5) # Scale to 1-5\n",
    "\n",
    "def compute_impermeability_score(material):\n",
    "    \"\"\"Calculates an impermeability score (1-3).\"\"\"\n",
    "    material = material.lower()\n",
    "    if material in [\"leather\", \"synthetic\"]: \n",
    "        return 3\n",
    "    if material in [\"denim\"]:\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "def compute_comfort_score(material, pattern):\n",
    "    \"\"\"Calculates a comfort score (1-5).\"\"\"\n",
    "    score = 0\n",
    "    # Material comfort\n",
    "    material = material.lower()\n",
    "    if material in [\"cotton\", \"knit\", \"silk\"]: score += 2\n",
    "    elif material in [\"leather\", \"denim\"]: score += 1\n",
    "    \n",
    "    # Pattern/Style Comfort (solid/no pattern is often more casual/comfortable)\n",
    "    if pattern.lower() in [\"pure color\", \"none\"]: score += 1\n",
    "    \n",
    "    return min(max(1, score), 5) # Scale to 1-5\n",
    "\n",
    "def compute_layering_score(garment_type):\n",
    "    \"\"\"Calculates a layering score (1-5) based on how easily it can be layered.\"\"\"\n",
    "    if garment_type == \"outer\":\n",
    "        return 5 # Designed to be worn over, high layering potential\n",
    "    if garment_type == \"inner\":\n",
    "        return 4 # Designed to be worn under, good layering potential\n",
    "    return 2 # Not a traditional layer (e.g., pants, shoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26339c63",
   "metadata": {},
   "source": [
    "2. Gemini Vision Prompt\n",
    "\n",
    "This prompt is crucial. It instructs the model to act as a clothing expert, analyze the image, and return a clean, structured JSON object containing all necessary visual attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1026ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "You are analyzing a photo of a *single* clothing garment.\n",
    "\n",
    "TASK 1: Extract the garment's visual attributes and shape details.\n",
    "TASK 2: Return ALL details in a single, valid JSON object.\n",
    "\n",
    "Rules:\n",
    "- Assume the image contains only ONE primary garment.\n",
    "- For shape, focus on the garment itself (e.g., sleeve type, fit).\n",
    "- If an attribute is not clearly visible or applicable (e.g., 'sleeve' on pants), use \"none\".\n",
    "\n",
    "Return ONLY valid JSON:\n",
    "\n",
    "{\n",
    "  \"category\": \"t-shirt | button-up shirt | sweater | coat | jacket | jeans | trousers | shorts | skirt | dress | shoes | accessory\",\n",
    "  \"material\": \"cotton | denim | leather | synthetic (nylon/polyester) | wool | knit | silk | linen | other | none\",\n",
    "  \"color\": \"dominant color name or pattern (e.g., 'light blue', 'red and white')\",\n",
    "  \"pattern\": \"pure color (solid) | floral | graphic (logo/text) | striped | plaid | none\",\n",
    "  \"shape_details\": {\n",
    "    \"sleeve\": \"long-sleeve | short-sleeve | sleeveless | none\",\n",
    "    \"neckline\": \"crew-neck | v-neck | collar | hoodie | none\",\n",
    "    \"fit\": \"slim | regular | oversized | tailored | none\"\n",
    "  },\n",
    "  \"notes\": \"short sentence describing the garment, e.g., 'A thick, oversized wool sweater.'\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bc89d7",
   "metadata": {},
   "source": [
    "3. Image Processing Loop\n",
    "\n",
    "This cell iterates through all images in the my_clothing_images/ folder, calls the Gemini model, and applies the feature engineering logic to compile the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390bf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found images to analyze: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing images: 100%|██████████| 46/46 [00:00<00:00, 3383.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Bottoms_01_Celana_Panjang_celana_panjang_legging_pensil__1695444457_8aebc02e_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Bottoms_04_Celana_Pendek_6505e289-1236-4675-8430-ebcc52fe4ca6.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Bottoms_04_Celana_Pendek_1a78d762-6f4b-49ef-81c1-05f934a95637.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_02_Kemeja_kemeja_flannel_kotakkotak_uniq_1675917050_301a8d20_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Bottoms_05_Celana_Panjang_uniqlo_celana_panjang_hitam_ka_1695917061_9338a1e0_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_04_Kaos_15c6d0c1-730d-4a7f-8534-7c7ca2ed8987.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_07_Kemeja_jual_kemeja_casual_salur_unbra_1678077047_48a607dd_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Outers_03_Jaket_Olahraga_spalding_down_jaket_pria_wanit_1696475515_9013a830_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Outers_04_Mantel_f5cc4125-f9b2-4d1c-b384-65f2263ef140.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Outers_01_Jaket_Olahraga_jaket_buat_olahraga_1687422779_21bf5ac7_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_01_Kemeja_kemeja_ruentex_bekas_second_pr_1694063664_dc8a7b84_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Bottoms_07_Jeans_celana_panjang_jeans_pria_the__1695039995_5ca2612d_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Bottoms_06_Celana_Panjang_local_brand_kuki_store_celana__1696658538_a4ff27e5_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_10_Kemeja_c4fb57e1-2d71-495e-881f-e85a7b40a0d9.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Outers_02_Jaket_Olahraga_jaket_olahraga_1685670762_21751e24_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_01_Kemeja_kemeja_anak_perempuan_uniqlo_o_1666148390_5d0cca52_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_03_Kaos_2fa9f4e6-ff5a-4ee1-9e74-ca1506331c17.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_05_Sweter_14c2f75c-458b-49cc-b3c7-5d4c30d416a7.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Bottoms_08_Celana_Pendek_celana_pendek_adidas_vintage_s_1694041106_526cc9f3_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_04_Kaos_259f2358-fb94-4e7e-bd05-864e28071c17.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_02_Kemeja_jual_kemeja_polos_casual_ma_bu_1679033102_3264cf28_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Bottoms_02_Celana_Pendek_celana_pendek_nike_hitam_bekas_1693666456_30153a48_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Bottoms_08_Celana_Pendek_celana_pendek_jeans_denim_unig_1684320839_9ed5af7d_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Outers_05_Jaket_Denim_guess_denim_jacket_original_10_1694606555_4dbb9257_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Bottoms_06_Celana_Panjang_crinkle_kulot_mix_atasan_bahan_1697055697_8d4034b2_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Outers_05_Jaket_Denim_tres_jolie_denim_jacket_1680188340_e1557cda_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_06_Sweter_33f8afe9-fe61-4b50-9d84-4d48d47f0916.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Outers_04_Mantel_grey_coat_1695231431_3cd1d518_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Outers_01_Jaket_Olahraga_jaket_olahraga_1650862706_c339a5ea_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_09_Kaos_5f0a3fa0-6a3d-4b68-b213-72766a643de7.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_09_Kaos_84c5becd-3bbc-4f8d-8aff-45a918cbfe89.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Bottoms_03_Jeans_vintage_levis_201xx_1930s_dark_1680598110_146dc916_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_03_Kaos_362b7a23-f85d-4a44-9463-347e34fae2c2.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_07_Kemeja_c88db196-c8a6-4ee7-9a62-7d1eaf33f0b4.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Bottoms_01_Celana_Panjang_crinkel_kulot__celana_panjang__1696799793_11494481_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_08_Kaos_07b294ee-9a04-4795-9af2-7a1c801e8db0.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Bottoms_02_Celana_Pendek_celana_pendek_everlast_tapped__1690431463_a156e16e_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_08_Kaos_3b89bb75-32bb-4e42-a8f7-a1648f5c20ad.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_06_Sweter_f0e2a88a-9286-44a8-95bd-2e21559c3b24.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Bottoms_03_Jeans_fac591c6-d884-44bf-9f73-3f9dd8e39c0a.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Outers_02_Jaket_Olahraga_jaket_k2_olahraga_sport_lari_j_1695638154_63008f21_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Bottoms_05_Celana_Panjang_hammerstout_long_cargo_pants_c_1696778232_05c9e40d_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_10_Kemeja_1c3deae2-1e34-4b42-b4e2-4932937481a9.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Outers_03_Jaket_Olahraga_jaket_olahraga_1695530189_61cc640e_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Bottoms_07_Jeans_celana_jeans_pria_slim_fit_oak_1692620409_8cc35637_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n",
      "Error processing Tops_05_Sweter_d4eea203-72d6-4f7a-a212-ed214c7567f0.jpg: module 'openai' has no attribute 'generate_content'\n",
      "\n",
      " Finished processing! Garment records created: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "final_results = []\n",
    "all_images = list(IMAGE_DIR.glob(\"*.jpg\"))\n",
    "\n",
    "if not all_images:\n",
    "    print(f\"No images found in {IMAGE_DIR}. Please check the folder.\")\n",
    "\n",
    "print(f\"Found images to analyze: {len(all_images)}\")\n",
    "\n",
    "for img_path in tqdm(all_images, desc=\"Analyzing images\"):\n",
    "    image_link = str(img_path)\n",
    "    \n",
    "    try:\n",
    "        # Encode image to base64\n",
    "        with open(img_path, \"rb\") as image_file:\n",
    "            base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "        # 1. Send to OpenAI Vision API\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": PROMPT},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=500\n",
    "        )\n",
    "        text = response.choices[0].message.content\n",
    "        \n",
    "        # 2. Extract JSON\n",
    "        match = re.search(r\"{.*}\", text, re.DOTALL)\n",
    "        if not match:\n",
    "            print(f\"Skipping {img_path.name}: Failed to extract JSON.\")\n",
    "            continue\n",
    "            \n",
    "        gemini_data = json.loads(match.group())\n",
    "\n",
    "        # 3. Compute derived features\n",
    "        category = gemini_data.get(\"category\", \"unknown\")\n",
    "        material = gemini_data.get(\"material\", \"none\")\n",
    "        \n",
    "        garment_type = determine_outer_inner(category)\n",
    "        warmth_score = compute_warmth_score(material, category)\n",
    "        impermeability_score = compute_impermeability_score(material)\n",
    "        comfort_score = compute_comfort_score(material, gemini_data.get(\"pattern\", \"none\"))\n",
    "        layering_score = compute_layering_score(garment_type)\n",
    "        \n",
    "        # 4. Build final dataset row\n",
    "        final_row = {\n",
    "            \"image_link\": image_link,\n",
    "            \"category\": category,\n",
    "            \"outer_inner\": garment_type,\n",
    "            \"shape\": gemini_data.get(\"shape_details\", {}),\n",
    "            \"material\": material,\n",
    "            \"color\": gemini_data.get(\"color\", \"unknown\"),\n",
    "            \"pattern\": gemini_data.get(\"pattern\", \"none\"),\n",
    "            \"warmth_score\": warmth_score,\n",
    "            \"layering_score\": layering_score,\n",
    "            \"impermeability_score\": impermeability_score,\n",
    "            \"comfort_score\": comfort_score,\n",
    "            \"notes\": gemini_data.get(\"notes\", \"\")\n",
    "        }\n",
    "\n",
    "        final_results.append(final_row)\n",
    "        time.sleep(1)  # Reduced from 10s to 1s for OpenAI rate limits\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n Finished processing! Garment records created: {len(final_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768dd8a8",
   "metadata": {},
   "source": [
    "4. Save and Review Dataset\n",
    "\n",
    "Finally, the results are saved to a JSON file and the first record is printed for a quick check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e06c382d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset not created as no images were processed successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- SAVE DATASET AS JSON ---\n",
    "if final_results:\n",
    "    with open(OUTPUT_FILE, 'w') as f:\n",
    "        json.dump(final_results, f, indent=4)\n",
    "\n",
    "    print(f\"Dataset successfully saved to {OUTPUT_FILE}\")\n",
    "\n",
    "    # Display a sample of the results\n",
    "    print(\"\\n--- Sample Record ---\")\n",
    "    print(json.dumps(final_results[0], indent=4))\n",
    "else:\n",
    "    print(\"Dataset not created as no images were processed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29049954",
   "metadata": {},
   "source": [
    "##### Adding new clothing to dataset\n",
    "It needs to run prompt cell and configuration cell first \n",
    "\n",
    "**WARNING** Don't run the imageprocessing loop unless you are adding an entirely new wardrobe to the system in one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_single_garment_to_dataset(new_image_path, existing_data_path):\n",
    "    \"\"\"\n",
    "    Analyzes a single new garment image, computes its features, and appends\n",
    "    the new record to the existing dataset JSON file.\n",
    "    \"\"\"\n",
    "    new_image_path = Path(new_image_path)\n",
    "    if not new_image_path.is_file():\n",
    "        print(f\"Error: Image file not found at {new_image_path}\")\n",
    "        return\n",
    "\n",
    "    # 1. Load Existing Dataset\n",
    "    existing_results = []\n",
    "    if existing_data_path.exists():\n",
    "        try:\n",
    "            with open(existing_data_path, 'r') as f:\n",
    "                existing_results = json.load(f)\n",
    "            print(f\"Loaded {len(existing_results)} existing records.\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Warning: Existing dataset file is corrupted or empty. Starting new dataset.\")\n",
    "\n",
    "    image_link = str(new_image_path)\n",
    "    \n",
    "    # 2. Check for Duplicates\n",
    "    if any(item.get('image_link') == image_link for item in existing_results):\n",
    "        print(f\"Warning: {new_image_path.name} already exists in the dataset. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # --- Processing the New Image ---\n",
    "    print(f\"\\n Analyzing new item: {new_image_path.name}\")\n",
    "    try:\n",
    "        # Encode image to base64\n",
    "        with open(new_image_path, \"rb\") as image_file:\n",
    "            base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "        # A. Send to OpenAI Vision API\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": PROMPT},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=500\n",
    "        )\n",
    "        text = response.choices[0].message.content\n",
    "        \n",
    "        # B. Extract JSON\n",
    "        match = re.search(r\"{.*}\", text, re.DOTALL)\n",
    "        if not match:\n",
    "            print(f\"Failed to extract JSON from OpenAI for {new_image_path.name}.\")\n",
    "            return\n",
    "            \n",
    "        gemini_data = json.loads(match.group())\n",
    "\n",
    "        # C. Compute derived features\n",
    "        category = gemini_data.get(\"category\", \"unknown\")\n",
    "        material = gemini_data.get(\"material\", \"none\")\n",
    "        \n",
    "        # Use global feature engineering functions\n",
    "        garment_type = determine_outer_inner(category)\n",
    "        warmth_score = compute_warmth_score(material, category)\n",
    "        impermeability_score = compute_impermeability_score(material)\n",
    "        comfort_score = compute_comfort_score(material, gemini_data.get(\"pattern\", \"none\"))\n",
    "        layering_score = compute_layering_score(garment_type)\n",
    "        \n",
    "        # D. Build final dataset row\n",
    "        new_row = {\n",
    "            \"image_link\": image_link,\n",
    "            \"category\": category,\n",
    "            \"outer_inner\": garment_type,\n",
    "            \"shape\": gemini_data.get(\"shape_details\", {}),\n",
    "            \"material\": material,\n",
    "            \"color\": gemini_data.get(\"color\", \"unknown\"),\n",
    "            \"pattern\": gemini_data.get(\"pattern\", \"none\"),\n",
    "            \"warmth_score\": warmth_score,\n",
    "            \"layering_score\": layering_score,\n",
    "            \"impermeability_score\": impermeability_score,\n",
    "            \"comfort_score\": comfort_score,\n",
    "            \"notes\": gemini_data.get(\"notes\", \"\")\n",
    "        }\n",
    "\n",
    "        # 3. Append and Save\n",
    "        existing_results.append(new_row)\n",
    "        with open(existing_data_path, 'w') as f:\n",
    "            json.dump(existing_results, f, indent=4)\n",
    "\n",
    "        print(f\"Success! {new_image_path.name} added to dataset.\")\n",
    "        print(f\"Total records now: {len(existing_results)}\")\n",
    "        print(\"\\n--- New Record Summary ---\")\n",
    "        print(json.dumps(new_row, indent=4))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {new_image_path.name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68765be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 existing records.\n",
      "\n",
      " Analyzing new item: Outers_05_Jaket_Denim_guess_denim_jacket_original_10_1694606555_4dbb9257_progressive_thumbnail.jpg\n",
      "Error processing Outers_05_Jaket_Denim_guess_denim_jacket_original_10_1694606555_4dbb9257_progressive_thumbnail.jpg: module 'openai' has no attribute 'generate_content'\n"
     ]
    }
   ],
   "source": [
    "# --- EXAMPLE USAGE: Add a single new item ---\n",
    "\n",
    "# NOTE: Replace 'path/to/your/new_item.jpg' with the actual path \n",
    "# where the user saves their new clothing image.\n",
    "NEW_ITEM_PATH = \"simulated_wardrobes/Male_Wardrobe/Outers_05_Jaket_Denim_guess_denim_jacket_original_10_1694606555_4dbb9257_progressive_thumbnail.jpg\" \n",
    "\n",
    "# Assume the user copies their new photo into the Male_Wardrobe folder\n",
    "# For demonstration, you might need to create a dummy image at that path first.\n",
    "\n",
    "add_single_garment_to_dataset(NEW_ITEM_PATH, OUTPUT_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
