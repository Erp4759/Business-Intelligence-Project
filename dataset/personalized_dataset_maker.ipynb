{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b95e365d",
   "metadata": {},
   "source": [
    "## VAESTA Project: Personalized Garment Dataset Creation\n",
    "\n",
    "This notebook uses the Gemini Vision model to analyze user-provided images of single clothing items, extract visual attributes, and compute derived features (like warmth, comfort, and layering scores) to create a rich, structured JSON dataset.\n",
    "\n",
    "0. Initial Setup\n",
    "\n",
    "Install Dependencies (Run this cell once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a737b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow google-generativeai tqdm pandas --quiet\n",
    "!pip install openai --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cba4f9",
   "metadata": {},
   "source": [
    "Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6546d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API configured (model: gpt-4o-mini)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "OPENAI_API_KEY = \"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\"  # Replace with your actual OpenAI API key\n",
    "IMAGE_DIR = Path(\"simulated_wardrobes/Female_Wardrobe/\")\n",
    "OUTPUT_FILE = Path(\"personalized_clothing_dataset_female.json\")\n",
    "# IMAGE_DIR = Path(\"simulated_wardrobes/Male_Wardrobe\")\n",
    "# OUTPUT_FILE = Path(\"personalized_clothing_dataset_male.json\")\n",
    "MODEL_NAME = \"gpt-4o-mini\"  # OpenAI vision model\n",
    "\n",
    "# Ensure image directory exists\n",
    "if not IMAGE_DIR.is_dir():\n",
    "    print(f\"Creating image directory at {IMAGE_DIR}. Please add your images now.\")\n",
    "    IMAGE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --- Configure OpenAI ---\n",
    "try:\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    print(f\"OpenAI API configured (model: {MODEL_NAME})\")\n",
    "except Exception as e:\n",
    "    print(f\"Error configuring OpenAI: {e}\")\n",
    "    # Exit or handle error if API key is invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1db3e",
   "metadata": {},
   "source": [
    "1. Feature Engineering Logic\n",
    "\n",
    "These functions translate the raw visual attributes extracted by Gemini (Category, Material, Pattern) into the required quantitative scores (Warmth, Impermeability, Comfort, and Layering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7a0adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping to determine basic garment type\n",
    "OUTER_GARMENTS = [\"coat\", \"jacket\", \"cardigan\", \"blazer\", \"hoodie\"]\n",
    "\n",
    "def determine_outer_inner(category):\n",
    "    \"\"\"Classifies a garment as 'outer' or 'inner' based on category.\"\"\"\n",
    "    category = category.lower()\n",
    "    if category in OUTER_GARMENTS:\n",
    "        return \"outer\"\n",
    "    elif category in [\"dress\", \"skirt\", \"pants\", \"shorts\", \"shoes\", \"accessory\"]:\n",
    "        return \"not-applicable\" # E.g., not an upper body layer\n",
    "    return \"inner\" # Default for t-shirts, shirts, sweaters, etc.\n",
    "\n",
    "def compute_warmth_score(material, category):\n",
    "    \"\"\"Calculates a warmth score (1-5) based on material and garment type.\"\"\"\n",
    "    fabric_scores = {\"denim\":3,\"cotton\":2,\"leather\":4,\"furry\":5,\"wool\":5,\"knit\":4,\"chiffon\":1,\"synthetic\":3,\"silk\":2,\"linen\":1,\"other\":2}\n",
    "    \n",
    "    base_score = fabric_scores.get(material.lower(), 2)\n",
    "    \n",
    "    if category.lower() in OUTER_GARMENTS:\n",
    "        base_score += 2 # Outer garments typically add more warmth\n",
    "    elif category.lower() == \"dress\":\n",
    "        base_score += 1 # Dresses cover a large area\n",
    "        \n",
    "    return min(max(1, base_score), 5) # Scale to 1-5\n",
    "\n",
    "def compute_impermeability_score(material):\n",
    "    \"\"\"Calculates an impermeability score (1-3).\"\"\"\n",
    "    material = material.lower()\n",
    "    if material in [\"leather\", \"synthetic\"]: \n",
    "        return 3\n",
    "    if material in [\"denim\"]:\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "def compute_comfort_score(material, pattern):\n",
    "    \"\"\"Calculates a comfort score (1-5).\"\"\"\n",
    "    score = 0\n",
    "    # Material comfort\n",
    "    material = material.lower()\n",
    "    if material in [\"cotton\", \"knit\", \"silk\"]: score += 2\n",
    "    elif material in [\"leather\", \"denim\"]: score += 1\n",
    "    \n",
    "    # Pattern/Style Comfort (solid/no pattern is often more casual/comfortable)\n",
    "    if pattern.lower() in [\"pure color\", \"none\"]: score += 1\n",
    "    \n",
    "    return min(max(1, score), 5) # Scale to 1-5\n",
    "\n",
    "def compute_layering_score(garment_type):\n",
    "    \"\"\"Calculates a layering score (1-5) based on how easily it can be layered.\"\"\"\n",
    "    if garment_type == \"outer\":\n",
    "        return 5 # Designed to be worn over, high layering potential\n",
    "    if garment_type == \"inner\":\n",
    "        return 4 # Designed to be worn under, good layering potential\n",
    "    return 2 # Not a traditional layer (e.g., pants, shoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26339c63",
   "metadata": {},
   "source": [
    "2. Gemini Vision Prompt\n",
    "\n",
    "This prompt is crucial. It instructs the model to act as a clothing expert, analyze the image, and return a clean, structured JSON object containing all necessary visual attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1026ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "You are analyzing a photo of a *single* clothing garment.\n",
    "\n",
    "TASK 1: Extract the garment's visual attributes and shape details.\n",
    "TASK 2: Return ALL details in a single, valid JSON object.\n",
    "\n",
    "Rules:\n",
    "- Assume the image contains only ONE primary garment.\n",
    "- For shape, focus on the garment itself (e.g., sleeve type, fit).\n",
    "- If an attribute is not clearly visible or applicable (e.g., 'sleeve' on pants), use \"none\".\n",
    "\n",
    "Return ONLY valid JSON:\n",
    "\n",
    "{\n",
    "  \"category\": \"t-shirt | button-up shirt | sweater | coat | jacket | jeans | trousers | shorts | skirt | dress | shoes | accessory\",\n",
    "  \"material\": \"cotton | denim | leather | synthetic (nylon/polyester) | wool | knit | silk | linen | other | none\",\n",
    "  \"color\": \"dominant color name or pattern (e.g., 'light blue', 'red and white')\",\n",
    "  \"pattern\": \"pure color (solid) | floral | graphic (logo/text) | striped | plaid | none\",\n",
    "  \"shape_details\": {\n",
    "    \"sleeve\": \"long-sleeve | short-sleeve | sleeveless | none\",\n",
    "    \"neckline\": \"crew-neck | v-neck | collar | hoodie | none\",\n",
    "    \"fit\": \"slim | regular | oversized | tailored | none\"\n",
    "  },\n",
    "  \"notes\": \"short sentence describing the garment, e.g., 'A thick, oversized wool sweater.'\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bc89d7",
   "metadata": {},
   "source": [
    "3. Image Processing Loop\n",
    "\n",
    "This cell iterates through all images in the my_clothing_images/ folder, calls the Gemini model, and applies the feature engineering logic to compile the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4390bf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found images to analyze: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing images: 100%|██████████| 250/250 [16:55<00:00,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Finished processing! Garment records created: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "final_results = []\n",
    "all_images = list(IMAGE_DIR.glob(\"*.jpg\"))\n",
    "\n",
    "if not all_images:\n",
    "    print(f\"No images found in {IMAGE_DIR}. Please check the folder.\")\n",
    "\n",
    "print(f\"Found images to analyze: {len(all_images)}\")\n",
    "\n",
    "for img_path in tqdm(all_images, desc=\"Analyzing images\"):\n",
    "    image_link = str(img_path)\n",
    "    \n",
    "    try:\n",
    "        # Encode image to base64\n",
    "        with open(img_path, \"rb\") as image_file:\n",
    "            base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "        # 1. Send to OpenAI Vision API\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": PROMPT},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=500\n",
    "        )\n",
    "        text = response.choices[0].message.content\n",
    "        \n",
    "        # 2. Extract JSON\n",
    "        match = re.search(r\"{.*}\", text, re.DOTALL)\n",
    "        if not match:\n",
    "            print(f\"Skipping {img_path.name}: Failed to extract JSON.\")\n",
    "            continue\n",
    "            \n",
    "        gemini_data = json.loads(match.group())\n",
    "\n",
    "        # 3. Compute derived features\n",
    "        category = gemini_data.get(\"category\", \"unknown\")\n",
    "        material = gemini_data.get(\"material\", \"none\")\n",
    "        \n",
    "        garment_type = determine_outer_inner(category)\n",
    "        warmth_score = compute_warmth_score(material, category)\n",
    "        impermeability_score = compute_impermeability_score(material)\n",
    "        comfort_score = compute_comfort_score(material, gemini_data.get(\"pattern\", \"none\"))\n",
    "        layering_score = compute_layering_score(garment_type)\n",
    "        \n",
    "        # 4. Build final dataset row\n",
    "        final_row = {\n",
    "            \"image_link\": image_link,\n",
    "            \"category\": category,\n",
    "            \"outer_inner\": garment_type,\n",
    "            \"shape\": gemini_data.get(\"shape_details\", {}),\n",
    "            \"material\": material,\n",
    "            \"color\": gemini_data.get(\"color\", \"unknown\"),\n",
    "            \"pattern\": gemini_data.get(\"pattern\", \"none\"),\n",
    "            \"warmth_score\": warmth_score,\n",
    "            \"layering_score\": layering_score,\n",
    "            \"impermeability_score\": impermeability_score,\n",
    "            \"comfort_score\": comfort_score,\n",
    "            \"notes\": gemini_data.get(\"notes\", \"\")\n",
    "        }\n",
    "\n",
    "        final_results.append(final_row)\n",
    "        time.sleep(1)  # Reduced from 10s to 1s for OpenAI rate limits\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n Finished processing! Garment records created: {len(final_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768dd8a8",
   "metadata": {},
   "source": [
    "4. Save and Review Dataset\n",
    "\n",
    "Finally, the results are saved to a JSON file and the first record is printed for a quick check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e06c382d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully saved to personalized_clothing_dataset_male.json\n",
      "\n",
      "--- Sample Record ---\n",
      "{\n",
      "    \"image_link\": \"simulated_wardrobes/Male_Wardrobe/Tops_00248_Polo_kaos_polo_shirt_kerah_lengan_p_1690729706_39121122_progressive_thumbnail.jpg\",\n",
      "    \"category\": \"button-up shirt\",\n",
      "    \"outer_inner\": \"inner\",\n",
      "    \"shape\": {\n",
      "        \"sleeve\": \"short-sleeve\",\n",
      "        \"neckline\": \"collar\",\n",
      "        \"fit\": \"regular\"\n",
      "    },\n",
      "    \"material\": \"cotton\",\n",
      "    \"color\": \"light blue\",\n",
      "    \"pattern\": \"striped\",\n",
      "    \"warmth_score\": 2,\n",
      "    \"layering_score\": 4,\n",
      "    \"impermeability_score\": 1,\n",
      "    \"comfort_score\": 2,\n",
      "    \"notes\": \"A light blue striped button-up shirt with a collar.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# --- SAVE DATASET AS JSON ---\n",
    "if final_results:\n",
    "    with open(OUTPUT_FILE, 'w') as f:\n",
    "        json.dump(final_results, f, indent=4)\n",
    "\n",
    "    print(f\"Dataset successfully saved to {OUTPUT_FILE}\")\n",
    "\n",
    "    # Display a sample of the results\n",
    "    print(\"\\n--- Sample Record ---\")\n",
    "    print(json.dumps(final_results[0], indent=4))\n",
    "else:\n",
    "    print(\"Dataset not created as no images were processed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29049954",
   "metadata": {},
   "source": [
    "##### Adding new clothing to dataset\n",
    "It needs to run prompt cell and configuration cell first \n",
    "\n",
    "**WARNING** Don't run the imageprocessing loop unless you are adding an entirely new wardrobe to the system in one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa0b8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_single_garment_to_dataset(new_image_path, existing_data_path):\n",
    "    \"\"\"\n",
    "    Analyzes a single new garment image, computes its features, and appends\n",
    "    the new record to the existing dataset JSON file.\n",
    "    \"\"\"\n",
    "    new_image_path = Path(new_image_path)\n",
    "    if not new_image_path.is_file():\n",
    "        print(f\"Error: Image file not found at {new_image_path}\")\n",
    "        return\n",
    "\n",
    "    # 1. Load Existing Dataset\n",
    "    existing_results = []\n",
    "    if existing_data_path.exists():\n",
    "        try:\n",
    "            with open(existing_data_path, 'r') as f:\n",
    "                existing_results = json.load(f)\n",
    "            print(f\"Loaded {len(existing_results)} existing records.\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Warning: Existing dataset file is corrupted or empty. Starting new dataset.\")\n",
    "\n",
    "    image_link = str(new_image_path)\n",
    "    \n",
    "    # 2. Check for Duplicates\n",
    "    if any(item.get('image_link') == image_link for item in existing_results):\n",
    "        print(f\"Warning: {new_image_path.name} already exists in the dataset. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # --- Processing the New Image ---\n",
    "    print(f\"\\n Analyzing new item: {new_image_path.name}\")\n",
    "    try:\n",
    "        # Encode image to base64\n",
    "        with open(new_image_path, \"rb\") as image_file:\n",
    "            base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "        # A. Send to OpenAI Vision API\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": PROMPT},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=500\n",
    "        )\n",
    "        text = response.choices[0].message.content\n",
    "        \n",
    "        # B. Extract JSON\n",
    "        match = re.search(r\"{.*}\", text, re.DOTALL)\n",
    "        if not match:\n",
    "            print(f\"Failed to extract JSON from OpenAI for {new_image_path.name}.\")\n",
    "            return\n",
    "            \n",
    "        gemini_data = json.loads(match.group())\n",
    "\n",
    "        # C. Compute derived features\n",
    "        category = gemini_data.get(\"category\", \"unknown\")\n",
    "        material = gemini_data.get(\"material\", \"none\")\n",
    "        \n",
    "        # Use global feature engineering functions\n",
    "        garment_type = determine_outer_inner(category)\n",
    "        warmth_score = compute_warmth_score(material, category)\n",
    "        impermeability_score = compute_impermeability_score(material)\n",
    "        comfort_score = compute_comfort_score(material, gemini_data.get(\"pattern\", \"none\"))\n",
    "        layering_score = compute_layering_score(garment_type)\n",
    "        \n",
    "        # D. Build final dataset row\n",
    "        new_row = {\n",
    "            \"image_link\": image_link,\n",
    "            \"category\": category,\n",
    "            \"outer_inner\": garment_type,\n",
    "            \"shape\": gemini_data.get(\"shape_details\", {}),\n",
    "            \"material\": material,\n",
    "            \"color\": gemini_data.get(\"color\", \"unknown\"),\n",
    "            \"pattern\": gemini_data.get(\"pattern\", \"none\"),\n",
    "            \"warmth_score\": warmth_score,\n",
    "            \"layering_score\": layering_score,\n",
    "            \"impermeability_score\": impermeability_score,\n",
    "            \"comfort_score\": comfort_score,\n",
    "            \"notes\": gemini_data.get(\"notes\", \"\")\n",
    "        }\n",
    "\n",
    "        # 3. Append and Save\n",
    "        existing_results.append(new_row)\n",
    "        with open(existing_data_path, 'w') as f:\n",
    "            json.dump(existing_results, f, indent=4)\n",
    "\n",
    "        print(f\"Success! {new_image_path.name} added to dataset.\")\n",
    "        print(f\"Total records now: {len(existing_results)}\")\n",
    "        print(\"\\n--- New Record Summary ---\")\n",
    "        print(json.dumps(new_row, indent=4))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {new_image_path.name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68765be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Image file not found at simulated_wardrobes/Male_Wardrobe/Outers_05_Jaket_Denim_guess_denim_jacket_original_10_1694606555_4dbb9257_progressive_thumbnail.jpg\n"
     ]
    }
   ],
   "source": [
    "# --- EXAMPLE USAGE: Add a single new item ---\n",
    "\n",
    "# NOTE: Replace 'path/to/your/new_item.jpg' with the actual path \n",
    "# where the user saves their new clothing image.\n",
    "NEW_ITEM_PATH = \"simulated_wardrobes/Male_Wardrobe/Outers_05_Jaket_Denim_guess_denim_jacket_original_10_1694606555_4dbb9257_progressive_thumbnail.jpg\" \n",
    "\n",
    "# Assume the user copies their new photo into the Male_Wardrobe folder\n",
    "# For demonstration, you might need to create a dummy image at that path first.\n",
    "\n",
    "add_single_garment_to_dataset(NEW_ITEM_PATH, OUTPUT_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
